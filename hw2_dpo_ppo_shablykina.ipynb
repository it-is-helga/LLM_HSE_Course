{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f",
      "metadata": {
        "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f"
      },
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 2: DPO –∏ PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51",
      "metadata": {
        "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51"
      },
      "source": [
        "–í —ç—Ç–æ–π –¥–æ–º–∞—à–∫–µ –ø–æ–±–ª–∏–∂–µ –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –¥–≤—É–º—è –∫—Ä–∞–π–Ω–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∞–ª–∞–π–º–µ–Ω—Ç–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –í –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –≤–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –∑–∞–∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ç—å DPO c –Ω—É–ª—è. –í–æ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏ –º—ã —É–∂–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É TRL –∏ –æ–±—É—á–∏–º PPO.\n",
        "\n",
        "–û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ –≤—ã–ª–æ–∂–∏—Ç—å –Ω–∞ [ü§ó HuggingFace](https://huggingface.co/). –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å —Ç–∞–º, –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ [deep vk](https://huggingface.co/deepvk) –∏ —Å–æ–∑–¥–∞–π—Ç–µ —Å–µ–±–µ API —Ç–æ–∫–µ–Ω.\n",
        "\n",
        "–°–ª–µ–¥—É–π—Ç–µ —è—á–µ–π–∫–∞–º —Ç–µ—Ç—Ä–∞–¥–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–π—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏. –í –∫–æ–Ω—Ü–µ —Ç–µ—Ç—Ä–∞–¥–∫–∏ –≤—ã –Ω–∞–π–¥–µ—Ç–µ –∑–∞–¥–∞—á–∏ —Å–æ –∑–≤–µ–∑–¥–æ—á–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b",
      "metadata": {
        "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b"
      },
      "source": [
        "## –ò–º–ø–æ—Ä—Ç—ã –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4",
      "metadata": {
        "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4"
      },
      "outputs": [],
      "source": [
        "# –£—Å—Ç–∞–Ω–æ–≤–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "%pip install --quiet datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
      "metadata": {
        "editable": true,
        "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã (–¥–ª—è –æ–±–æ–∏—Ö —á–∞—Å—Ç–µ–π)\n",
        "import inspect\n",
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi, interpreter_login\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedTokenizerBase,\n",
        ")\n",
        "from trl import PPOConfig, PPOTrainer, RewardConfig, RewardTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8464f5",
      "metadata": {
        "id": "0a8464f5"
      },
      "outputs": [],
      "source": [
        "interpreter_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce75b35",
      "metadata": {
        "id": "7ce75b35"
      },
      "outputs": [],
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –±—É–¥—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
        "username = HfApi().whoami()[\"name\"]\n",
        "REPO_NAME = f\"{username}/llm-course-hw2\"  # –ò–ª–∏ –∫–∞–∫ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è\n",
        "\n",
        "print(f\"Homework repository: '{REPO_NAME}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
      "metadata": {
        "editable": true,
        "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# –≠—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –±—É–¥—É—Ç –ø–æ–º–µ—á–µ–Ω—ã –≤—Å–µ –º–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å\n",
        "# –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Ü–µ–ª—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–∫ –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö\n",
        "# –í—Å–µ–≥–¥–∞ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏–µ–π –∏ –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ :)\n",
        "def todo():\n",
        "    stack = inspect.stack()\n",
        "    caller_frame = stack[1]\n",
        "    function_name = caller_frame.function\n",
        "    line_number = caller_frame.lineno\n",
        "    raise NotImplementedError(f\"TODO at {function_name}, line {line_number}\")\n",
        "\n",
        "\n",
        "def disable_dropout_in_model(model):\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, torch.nn.Dropout):\n",
        "            module.p = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
      "metadata": {
        "editable": true,
        "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
        "tags": []
      },
      "source": [
        "# –ß–∞—Å—Ç—å 1: DPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2",
      "metadata": {
        "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2"
      },
      "source": [
        "–ö—Ä–∞–π–Ω–µ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–≤–æ–µ –≤—Ä–µ–º—è –ø—Ä–æ–∏–∑–≤–µ–ª —Ñ—É—Ä–æ—Ä, —Ç.–∫. –≤—ã–≥–æ–¥–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è –Ω–∞ —Ñ–æ–Ω–µ PPO. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç PPO, —Ç—Ä–µ–±—É—é—â–µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ –æ–±—É—á–∞—Ç—å Reward Model, Value Model –∏ –±–æ–ª—å—à–∏—Ö —É—Å–∏–ª–∏–π –≤ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏, DPO –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–π —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª–∏, –∞ —Ç–æ–ª—å–∫–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏ –≤–∏–¥–∞: –ø—Ä–æ–º–ø—Ç, –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç, –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç. –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ç–∞–∫–∂–µ –≤–∏–¥–Ω–∞ –∏–∑ –ª–æ—Å—Å–∞, –ø–æ —Å—É—Ç–∏ —ç—Ç–æ –≤–µ—Å—å –º–µ—Ç–æ–¥:\n",
        "$$\n",
        "L_\\text{DPO}(\\pi_{\\theta}; \\pi_\\text{ref}) = -E_{(x, y_w, y_l)\\sim D}\\left[\\log \\sigma \\left(\n",
        "\\beta \\log \\frac{\\pi_{\\theta}(y_w\\mid x)}{\\pi_\\text{ref}(y_w\\mid x)} \\thinspace\n",
        "{- \\beta \\log \\frac{\\pi_{\\theta}(y_l\\mid x)}{\\pi_\\text{ref}(y_l\\mid x)}}\\right)\\right]\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "\n",
        "- $\\pi_{\\theta}$ LLM –∫–æ—Ç–æ—Ä—É—é –º—ã —Ö–æ—Ç–∏–º –∑–∞–∞–ª–∞–π–Ω–∏—Ç—å\n",
        "- $\\pi_\\text{ref}$ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–∞–ª—å–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç\n",
        "- $D$ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏\n",
        "- $x$ –ø—Ä–æ–º–ø—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ $D$\n",
        "- $y_w$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $y_l$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $\\beta$ –≥–∏–ø–µ—Ä–µ–ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ —Ç–æ, –∫–∞–∫ –¥–∞–ª–µ–∫–æ –º—ã –º–æ–∂–µ–º –æ—Ç—Ö–æ–¥–∏—Ç—å –æ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–í–æ –≤—Ä–µ–º—è –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ–≤–µ—Ç—É–º –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é: [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290).\n",
        "\n",
        "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∞ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å [HuggingFaceTB/SmolLM-135M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct), —Ç.–∫. –æ–Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–ø–æ–º–µ—Å—Ç–∏—Ç—Å—è –Ω–∞ Colab), –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º —É–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –∞–ª–∞–π–º–µ–Ω—Ç–∞. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞–∂–µ –ø—Ä–æ—à–ª–∞ —Å—Ç–∞–¥–∏—é SFT, –∞ –ø–æ—ç—Ç–æ–º—É –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–±–µ–∑ Instruct) –ø–æ–Ω–∏–º–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç —á–∞—Ç–∞ (chat-template –≤ transformers, –¥–∞–ª—å—à–µ —Ä–∞–∑–±–µ—Ä–µ–º) –∏ –∏–º–µ–µ—Ç '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ' —Å–µ–±—è —è–∑—ã–∫–æ–≤—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n",
        "\n",
        "P.S. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º —Ç–∏–ø–æ A100 –∏ –±–æ–ª—å—à–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞—Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑ —ç—Ç–æ–π –∂–µ [–ª–∏–Ω–µ–π–∫–∏](https://huggingface.co/blog/smollm). –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã, —Å–º–æ—Ç—Ä–∏—Ç–µ, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ —Å –¥–æ–±–∞–≤–∫–æ–π Instruct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d88765f",
      "metadata": {
        "id": "3d88765f"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
        "DATASET_ID = \"HumanLLMs/Human-Like-DPO-Dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963",
      "metadata": {
        "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963"
      },
      "source": [
        "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö [1 –±–∞–ª–ª]\n",
        "\n",
        "–î–ª—è –Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [HumanLLMs/Human-Like-DPO-Dataset](https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset), –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —ç–º–æ–¥–∑–∏ –∏ –≤ —Ü–µ–ª–æ–º —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç—Ä–æ–≥–æ—Å—Ç—å —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —à–∞–±–ª–æ–Ω—É \"As a conversational AI, I ...\".\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã—Ö —ç—Ç–∞–ø–æ–≤:\n",
        "1. –ü—Ä–∏–≤–µ—Å—Ç –¥–∞–Ω–Ω—ã–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É chat-template\n",
        "2. –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ—Ç chat-template —Å –ø–æ–º–æ—â—å—é 'tokenizer.apply_chat_template'\n",
        "3. –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ, –ø–æ–ø—É—Ç–Ω–æ –æ–±—Ä–µ–∑–∞–≤ –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–≤–µ—Ç—ã –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã, –µ—Å–ª–∏ –Ω–∞–¥–æ.\n",
        "\n",
        "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π—Ç–µ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ chat-templates](https://huggingface.co/docs/transformers/chat_templating). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –≤ –Ω–∞—á–∞–ª–µ –≤ –±–æ–ª–µ–µ –≤–µ—Ä—Ö–Ω–µ-—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–∞–∫–æ–≥–æ –≤–∏–¥–∞:\n",
        "```python\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models...\"}\n",
        "]\n",
        "```\n",
        "–¢–æ –µ—Å—Ç—å –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ä–æ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏ –≤ —Ü–µ–ª–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –∏ —á–µ–ª–æ–≤–µ–∫–æ–º. –û–±—ã—á–Ω–æ –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø–µ SFT. –î–∞–Ω–Ω–∞—è —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã) –∫–∞–∫ —ç—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. –ß—Ç–æ–±—ã –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –µ–≥–æ –≤ –Ω–µ—Å–ø–æ—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∏–Ω–ø—É—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `tokenizer.apply_chat_template`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6",
      "metadata": {
        "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6"
      },
      "outputs": [],
      "source": [
        "# –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d",
      "metadata": {
        "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964",
      "metadata": {
        "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964"
      },
      "source": [
        "–ü—Ä–∏–≤–µ–¥–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É —á–∞—Ç–∞, –≥–¥–µ —É –ø—Ä–æ–º–ø—Ç–∞ —Ä–æ–ª—å user, –∞ —É –æ—Ç–≤–µ—Ç–æ–≤ assistant, –∞ –ø–æ—Ç–æ–º –ø—Ä–∏–º–µ–Ω–∏—Ç–µ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff",
      "metadata": {
        "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff"
      },
      "outputs": [],
      "source": [
        "def apply_chat_template(example: dict[str, str], tokenizer: PreTrainedTokenizerBase) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Transforms a dataset example into a formatted chat template using the provided tokenizer.\n",
        "\n",
        "    Args:\n",
        "        example (Dict[str, str]): A dictionary containing the following keys:\n",
        "            - \"prompt\": The initial user prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): An object that provides the `apply_chat_template` method\n",
        "            for formatting the conversation.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary with the following keys:\n",
        "            - \"prompt\": The formatted prompt string including the generation prompt.\n",
        "            - \"chosen\": The formatted assistant's chosen response (with the prompt prefix removed).\n",
        "            - \"rejected\": The formatted assistant's rejected response (with the prompt prefix removed).\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff",
      "metadata": {
        "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35",
      "metadata": {
        "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35"
      },
      "source": [
        "–ü–æ—Å–ª–µ —ç—Ç–∏—Ö –¥–≤—É—Ö —ç—Ç–∞–ø–æ–≤ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫ (**–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ–ª–æ–∂–µ–Ω–∏–µ <|im_start|>assistant\\n**, —ç—Ç–æ –≤–∞–∂–Ω–æ!):\n",
        "```\n",
        "{\n",
        "    'prompt': \"<|im_start|>user\\nOh, I just saw the best meme - have you seen it <|im_end|>\\n<|im_start|>assistant\\n\",\n",
        "    'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£<|im_end|>\\n\",\n",
        "    'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\\n\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a94b01",
      "metadata": {
        "id": "a3a94b01"
      },
      "source": [
        "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, –æ–±—Ä–µ–∑–∞–≤ –¥–ª–∏–Ω—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ. –í –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ ID —Ç–æ–∫–µ–Ω–æ–≤:\n",
        "```\n",
        "Dataset({\n",
        "    features: ['prompt_input_ids', 'chosen_input_ids', 'rejected_input_ids'],\n",
        "    num_rows: 10884\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df",
      "metadata": {
        "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df"
      },
      "source": [
        "–û–±—Ä–µ–∑–∞–π—Ç–µ –ø—Ä–æ–º–ø—Ç —Å–ª–µ–≤–∞, –∞ –Ω–µ —Å –∫–æ–Ω—Ü–∞. –ü–æ–¥—É–º–∞–π—Ç–µ –ø–æ—á–µ–º—É —Ç–∞–∫ –ª—É—á—à–µ. **–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç**.\n",
        "\n",
        "    #========== TODO ==========\n",
        "    #     –í–∞—à –æ—Ç–≤–µ—Ç –∑–¥–µ—Å—å     =\n",
        "    #=========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8",
      "metadata": {
        "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8"
      },
      "outputs": [],
      "source": [
        "def tokenize_row(\n",
        "    example: dict[str, str],\n",
        "    tokenizer: PreTrainedTokenizerBase,\n",
        "    max_prompt_length: int = 512,\n",
        "    max_completion_length: int | None = None,\n",
        ") -> dict[str, list[int]]:\n",
        "    \"\"\"\n",
        "    Tokenizes a single row of a dataset example for use in language model training or evaluation.\n",
        "\n",
        "    This function processes an example containing textual fields for a prompt, a chosen response,\n",
        "    and a rejected response. It tokenizes each text field using the provided tokenizer. If specified,\n",
        "    it truncates the tokenized prompt to the last `max_prompt_length` tokens and the tokenized responses\n",
        "    (chosen and rejected) to the first `max_completion_length` tokens.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The initial prompt text.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): A tokenizer that converts text into token IDs. It must return a dictionary\n",
        "            with the key \"input_ids\" when called.\n",
        "        max_prompt_length (Optional[int], optional): Maximum number of tokens to retain for the prompt.\n",
        "            The function keeps the last `max_prompt_length` tokens. Defaults to 512.\n",
        "        max_completion_length (Optional[int], optional): Maximum number of tokens to retain for the completion\n",
        "            responses (chosen and rejected). The function keeps the first `max_completion_length` tokens.\n",
        "            If None, no truncation is applied. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[int]]: A dictionary containing:\n",
        "            - \"prompt_input_ids\": The token IDs for the prompt, possibly truncated.\n",
        "            - \"chosen_input_ids\": The token IDs for the chosen response, possibly truncated.\n",
        "            - \"rejected_input_ids\": The token IDs for the rejected response, possibly truncated.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902b567f",
      "metadata": {
        "id": "902b567f"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": 256,\n",
        "        \"max_completion_length\": None,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        ")\n",
        "\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6687c2-73a7-4ae9-972c-6603673e6401",
      "metadata": {
        "id": "4e6687c2-73a7-4ae9-972c-6603673e6401"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –Ω–∞–¥–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å DataLoader. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–¥–æ –Ω–∞–ø–∏—Å–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π `collate_fn` –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ:\n",
        "1. –ü—Ä–∏–Ω–∏–º–∞—Ç—å –ª–∏—Å—Ç –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –∫–ª—é—á–∞–º–∏ `prompt_input_ids`, `chosen_input_ids`, `rejected_input_ids`.\n",
        "2. –ü–∞–¥–¥–∏—Ç—å –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª—é—á—É. –ü–æ –∏—Ç–æ–≥—É `prompt_input_ids` –∏ `chosen_input_ids` –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã –≤–Ω—É—Ç—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∫–ª—é—á–µ–π –¥–ª–∏–Ω–∞ –±—ã–ª–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞.\n",
        "3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∞–¥–¥–∏–Ω–≥ –º–∞—Å–∫—É —Ç–∞–∫–æ–≥–æ –∂–µ —à–µ–π–ø–∞, –≥–¥–µ 0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–∞–¥–¥–∏–Ω–≥-—Ç–æ–∫–µ–Ω–æ–≤ –∏ 1 –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
        "\n",
        "–î–ª—è –ø–∞–¥–¥–∏–Ω–≥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `pad`. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–∫–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `tokenizer.pad_token_id` –∏ 0 –¥–ª—è –º–∞—Å–∫–∏. **–û–ø—è—Ç—å –∂–µ, –ø–æ–¥—É–º–∞–π—Ç–µ –æ—Ç–∫—É–¥–∞ –ª—É—á—à–µ –ø–∞–¥–¥–∏—Ç—å `prompt_input_ids`?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90431c77-694c-446b-bced-eae8124936fb",
      "metadata": {
        "id": "90431c77-694c-446b-bced-eae8124936fb"
      },
      "outputs": [],
      "source": [
        "def pad(tensors: list[torch.Tensor], padding_value: int = 0, padding_side: str = \"right\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Pads a list of tensors to the same size along their leading dimension.\n",
        "\n",
        "    Args:\n",
        "        tensors (list[torch.Tensor]): A list of tensors to be padded.\n",
        "            All tensors in the list should be of the same type and device.\n",
        "        padding_value (int, default=0): The value used to pad the tensors.\n",
        "        padding_side (str, default=\"right\"): Specifies which side of the tensor to apply padding: either 'left' or 'right'.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing all the padded tensors, [N; max_length]\n",
        "            where N is the number of tensors and `max_length` is the shape of the largest tensor.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()\n",
        "\n",
        "\n",
        "def pad_collate_fn(batch: list[dict[str, torch.Tensor]], pad_token_id: int) -> dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Collates and pads a batch of tokenized examples for model input.\n",
        "\n",
        "    This function takes a batch of examples where each example is a dictionary containing\n",
        "    token IDs for the prompt, the chosen response, and the rejected response. For each field,\n",
        "    it extracts the list of token IDs, creates a corresponding attention mask (with ones for each token),\n",
        "    and then pads the sequences using a `pad` function. The prompt sequences and their attention masks\n",
        "    are padded on the left, while the chosen and rejected sequences are padded on the right (default).\n",
        "\n",
        "    Args:\n",
        "        batch (list[dict[str, torch.Tensor]]): A list of dictionaries, where each dictionary has the keys:\n",
        "            - \"prompt_input_ids\": Tensor of token IDs for the prompt.\n",
        "            - \"chosen_input_ids\": Tensor of token IDs for the chosen response.\n",
        "            - \"rejected_input_ids\": Tensor of token IDs for the rejected response.\n",
        "        pad_token_id (int): Padding value for token IDs.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, torch.Tensor]: A dictionary containing the following keys with padded tensors:\n",
        "            - \"prompt_input_ids\": Padded token IDs for the prompt (padded on the left).\n",
        "            - \"prompt_attn_mask\": Padded attention mask for the prompt (padded on the left, with 1s for actual tokens).\n",
        "            - \"chosen_input_ids\": Padded token IDs for the chosen response.\n",
        "            - \"chosen_attn_mask\": Padded attention mask for the chosen response.\n",
        "            - \"rejected_input_ids\": Padded token IDs for the rejected response.\n",
        "            - \"rejected_attn_mask\": Padded attention mask for the rejected response.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    collate_fn=todo(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749c4e48-9566-4314-9145-799465036404",
      "metadata": {
        "id": "749c4e48-9566-4314-9145-799465036404"
      },
      "outputs": [],
      "source": [
        "next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628ab5cb-dd61-4f97-bd11-e790470119bf",
      "metadata": {
        "id": "628ab5cb-dd61-4f97-bd11-e790470119bf"
      },
      "source": [
        "## DPO Loss [2 –±–∞–ª–ª–∞]\n",
        "\n",
        "–ù–∞—á–Ω–µ–º —Å –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–∞–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å. –û–Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–∞—è, —Å–ª–µ–¥—É–π—Ç–µ —Ñ–æ—Ä–º—É–ª–µ –¥–æ—Å–ª–æ–≤–Ω–æ –∏ –≤—Å–µ –ø–æ–ª—É—á–∏—Ç—Å—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183621d5-0d24-446b-856b-037d4075231c",
      "metadata": {
        "id": "183621d5-0d24-446b-856b-037d4075231c"
      },
      "outputs": [],
      "source": [
        "def dpo_loss(\n",
        "    chosen_logps: torch.Tensor,\n",
        "    rejected_logps: torch.Tensor,\n",
        "    ref_chosen_logps: torch.Tensor,\n",
        "    ref_rejected_logps: torch.Tensor,\n",
        "    beta: float = 0.1,\n",
        ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Computes the Direct Preference Optimization (DPO) loss and associated reward metrics.\n",
        "\n",
        "    Args:\n",
        "        chosen_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the chosen responses.\n",
        "        rejected_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the rejected responses.\n",
        "        ref_chosen_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for chosen responses.\n",
        "        ref_rejected_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for rejected responses.\n",
        "        beta (float, optional): A scaling factor applied to the differences in log-probabilities. Defaults to 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]:\n",
        "            - loss (Tensor): The computed DPO loss as a scalar tensor.\n",
        "            - reward_accuracies (Tensor): The fraction of examples where the chosen reward exceeds the rejected reward.\n",
        "            - reward_margins (Tensor): The average difference between the chosen and rejected rewards.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8351081-cb90-4a02-9796-59db45944dce",
      "metadata": {
        "id": "f8351081-cb90-4a02-9796-59db45944dce"
      },
      "source": [
        "–î–ª—è —É–¥–æ–±—Å—Ç–∞ —Ç–∞–∫–∂–µ –æ–ø—Ä–µ–¥–µ–ª–∏–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø–æ –ª–æ–≥–∏—Ç–∞–º. –í–∞–º –Ω—É–∂–Ω–æ –≤—ã—Ç–∞—â–∏—Ç—å –ª–æ–≥–∏—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø—Ä–æ–º–ø—Ç–∞ –ø–µ—Ä–µ–¥ –∞–≥–≥—Ä–µ–≥–∞—Ü–∏–µ–π. –ú–∞—Å–∫–∞ –∑–¥–µ—Å—å —É–∂–µ –¥–∞–Ω–∞.\n",
        "\n",
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π—Ç–µ –∫–∞–∫ —Å–æ–æ—Ç–Ω–æ—Å—è—Ç—Å—è –ª–æ–≥–ø—Ä–æ–±—ã –∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã, –∏–Ω–∞—á–µ —Ä–∏—Å–∫—É–µ—Ç–µ –æ—à–∏–±–∏—Ç—å—Å—è –Ω–∞ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8",
      "metadata": {
        "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8"
      },
      "outputs": [],
      "source": [
        "def get_log_prob(logits: torch.Tensor, labels: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the log probability for each sequence in a batch.\n",
        "\n",
        "    Args:\n",
        "        logits (Tensor): A tensor of shape [batch_size, seq_len, vocab_size]\n",
        "            representing the model's output logits.\n",
        "        labels (Tensor): A tensor of shape [batch_size, seq_len] containing the target token indices.\n",
        "        mask (Tensor): A tensor of shape [batch_size, seq_len] indicating which tokens to include\n",
        "            in the log probability (e.g., 1 for valid tokens and 0 for padding or prompt).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A tensor of shape [batch_size,] containing the log probability for each sequence.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d528b248-2040-4605-b20a-6e43269a531c",
      "metadata": {
        "id": "d528b248-2040-4605-b20a-6e43269a531c"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ DPO [2 –±–∞–ª–ª–∞]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597a061a-def0-4dfe-ac5a-309044b08a79",
      "metadata": {
        "id": "597a061a-def0-4dfe-ac5a-309044b08a79"
      },
      "source": [
        "–ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –¥–∞—Ç–∞—Å–µ—Ç —Å –Ω—É–ª—è.\n",
        "–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –æ–±—ã—á–Ω—ã–º —Ü–∏–∫–ª–æ–º, –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤, –∫–ª–∞—Å—Å–æ–≤ –∏ –ø—Ä–æ—á–µ–≥–æ.\n",
        "–í—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –∫–∞–∫ —É–¥–æ–±–Ω–æ –≤–∞–º, –≥–ª–∞–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å.\n",
        "\n",
        "–í—Å–µ –Ω—É–∂–Ω–æ–µ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å, –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —ç—Ç–æ –≤—Å–µ –≤–º–µ—Å—Ç–µ.\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–ø—Ä–æ–±—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç+–≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏ –ø—Ä–æ–º–ø—Ç+–æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç—ã.\n",
        "–ù–µ –∑–∞–±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–±—Ä–∞—Ç—å –º–∞—Å–∫—É –¥–ª—è –ª–æ—Å—Å–∞.\n",
        "–í –∫–æ–Ω—Ü–µ –æ–±—Ä–µ–∑–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤—Ö–æ–¥—ã –¥–ª—è –º–æ–¥–µ–ª–∏ –¥–æ `MAX_SEQ_LEN` (—Å –Ω—É–∂–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã!).\n",
        "\n",
        "–û–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ —á–∞—Å –Ω–∞ Colab T4 GPU, 2 –º–∏–Ω—É—Ç –Ω–∞ H100. –í Colab –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float16 –∏ AMP.\n",
        "–ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–æ —Å–∫–µ–π–ª–∏–Ω–≥. –î–ª—è bf16 –æ–Ω –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.\n",
        "\n",
        "**NB**: –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Kaggle Notebooks, —Ç.–∫. –æ–Ω–∏ –Ω–µ –≤—ã–ª–µ—Ç–∞—é—Ç –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å —Ç–µ—Ç—Ä–∞–¥–∫–æ–π. –ò—Ö –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–ª—è—Ç—å –Ω–∞ —á–∞—Å –±–µ–∑ –±–æ—è–∑–Ω–∏, —á—Ç–æ –æ–Ω–∏ —É–ø–∞–¥—É—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46",
      "metadata": {
        "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16  # in colab make it smaller, or implement grad accumulation\n",
        "NUM_EPOCHS = 1\n",
        "LR = 5e-5\n",
        "MAX_SEQ_LEN = 1024  # this also can be adjusted\n",
        "MAX_PROMPT_LEN = 256 # this also can be adjusted\n",
        "MAX_COMPLETION_LEN = None\n",
        "BETA = 1.0\n",
        "\n",
        "# –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ W&B\n",
        "ENABLE_WANDB = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "print(f\"Using '{DEVICE}' device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c",
      "metadata": {
        "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    wandb.init(project=\"hw2-rlhf\", group=\"dpo\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "model.train()\n",
        "disable_dropout_in_model(model)\n",
        "\n",
        "ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "ref_model.eval()\n",
        "disable_dropout_in_model(ref_model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": MAX_PROMPT_LEN,\n",
        "        \"max_completion_length\": MAX_COMPLETION_LEN,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=False,\n",
        "    collate_fn=partial(pad_collate_fn, pad_token_id=tokenizer.pad_token_id),\n",
        ")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    losses, accs, margins = [], [], []\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Epoch\", leave=False)\n",
        "    for batch in pbar:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        # ========== TODO ==========\n",
        "        #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "        # ==========================\n",
        "\n",
        "        # 1. Concatenate the prompt and completion inputs for chosen & rejected\n",
        "        todo()\n",
        "\n",
        "        # 2. Calculate logits for current and reference models for chosen and rejected samples\n",
        "        todo()\n",
        "\n",
        "        # 3. Calculate log probs for all models (no concat as in TRL for simplicity and to save memory with smaller batch size)\n",
        "        todo()\n",
        "\n",
        "        # 4. Calculate loss\n",
        "        todo()\n",
        "\n",
        "        # 5. Make optimizer step\n",
        "        todo()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        accs.append(reward_accuracies.item())\n",
        "        margins.append(reward_margins.item())\n",
        "        pbar.set_postfix({\"Reward margins\": np.mean(margins), \"Reward acc\": np.mean(accs)})\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"loss\": loss.item(),\n",
        "                    \"train-reward-margins\": reward_margins.item(),\n",
        "                    \"train-reward-accuracy\": reward_accuracies.item(),\n",
        "                    \"epoch\": epoch,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570",
      "metadata": {
        "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570"
      },
      "source": [
        "–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è reward margins –∏ accuracy –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ —Ä–∞—Å—Ç–∏. –î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b739545-0c57-4ede-a874-788236b38420",
      "metadata": {
        "editable": true,
        "id": "8b739545-0c57-4ede-a874-788236b38420",
        "tags": []
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb73140",
      "metadata": {
        "id": "cbb73140"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "model.push_to_hub(f\"{REPO_NAME}-dpo\", private=True)\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-dpo\", private=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84318ed4-e3db-4151-88fc-cb00755e6b63",
      "metadata": {
        "id": "84318ed4-e3db-4151-88fc-cb00755e6b63"
      },
      "source": [
        "# –ß–∞—Å—Ç—å 2: PPO –∏ TRL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6",
      "metadata": {
        "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6"
      },
      "source": [
        "–í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –ø—Ä–æ—â–µ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ —Ç–æ, —á—Ç–æ–±—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ–π –±–∏–±–ª–æ—Ç–µ–∫–æ–π –¥–ª—è –∞–ª–∞–π–º–µ–Ω—Ç–∞ –æ—Ç huggingface - [TRL](https://huggingface.co/docs/trl/v0.15.0/index). C –ø–æ–º–æ—â—å—é TRL –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ–±—É—á–∏—Ç—å PPO, –∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–Ω–∞—á–∞–ª–µ –æ–±—É—á–∏—Ç—å Reward Model.\n",
        "\n",
        "**–õ–∏—Ä–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å—Ç—É–ø–ª–µ–Ω–∏–µ**: PPO –∏–º–µ–µ—Ç –ø–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω—É—é —Ä–µ–ø—É—Ç–∞—Ü–∏—é. –° –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–Ω—ã –≤ RL –æ–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è —á—É—Ç—å –ª–∏ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–∏–º–µ–Ω–∏–º—ã–º (–¥–æ —Å–∏—Ö –ø–æ—Ä) –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–≤–æ–¥–∏—Ç—Å—è —Å –ø–æ–ª-–ø–∏–Ω–∫–∞ –∏ –Ω–∞ –ª—é–±–æ–π –∑–∞–¥–∞—á–µ. –û—Å–Ω–æ–≤–Ω–æ–π –±–æ—Ç—Ç–ª–Ω–µ–∫ –¥–ª—è –Ω–µ–≥–æ - –¥–∞–Ω–Ω—ã–µ, —á–µ–º –±—ã—Å—Ç—Ä–µ–µ —Å–∏–º—É–ª—è—Ç–æ—Ä, —Ç–∞–º –±–æ–ª—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ –æ–Ω –≤–∞—à—É –∑–∞–¥–∞—á—É —Ä–µ—à–∏—Ç. –ü—Ä–∏–º–µ—Ä–æ–≤ –º–Ω–æ–≥–æ - —Ç–∞–∫ —Ä–µ—à–∏–ª–∏ Dota 2 –∏–ª–∏ Minecraft. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —É –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫—Ä–∞–π–Ω–µ –¥—É—Ä–Ω–∞—è —Ä–µ–ø—É—Ç–∞—Ü–∏—è –≤ –ø–ª–∞–Ω–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –Ω—É–ª—è, —Ç.–∫. –µ—Å—Ç—å –º–Ω–æ–≥–æ –≤–∞–∂–Ω—ã—Ö –∏ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–≤–µ–¥—É—Ç –∫ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ–º—É, –Ω–æ –∫—Ä–∞–π–Ω–µ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É –ø–æ–≤–µ–¥–µ–Ω–∏—é. –î–µ–±–∞–≥–∞—Ç—å —ç—Ç–æ –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ, [—á–µ–≥–æ —Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/) –∏ [—Ç–∞–∫–æ–π –∂–µ –¥–ª—è —É–∂–µ RLHF](https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo), –ø—Ä–∏—á–µ–º —á–∞—Å—Ç–æ —Ç—Ä—é–∫–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –∫–∞–∫ —Ä–∞–∑ –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ –µ—Å–ª–∏ –≤—ã –∑–∞–≥—É–≥–ª–∏—Ç–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ PPO —Å –Ω—É–ª—è, —Å –±–æ–ª—å—à–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å –æ—à–∏–±–∫–∞–º–∏.\n",
        "\n",
        "–ü–æ—ç—Ç–æ–º—É –∫–æ–¥–∏—Ç—å PPO –±–µ–∑ —Ç–µ—Å–Ω–æ–≥–æ –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞ –∏ –æ–ø—ã—Ç–∞ –≤ RL –∫—Ä–∞–π–Ω–µ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è. –î–ª—è RLHF –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TRL –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏, –¥–ª—è RL –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [Sample-Factory](https://github.com/alex-petrenko/sample-factory)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1616be4-4106-49a6-8c7f-155081d7263d",
      "metadata": {
        "id": "d1616be4-4106-49a6-8c7f-155081d7263d"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ Reward Model [1 –±–∞–ª–ª]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae",
      "metadata": {
        "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae"
      },
      "source": [
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç DPO, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–≤–æ–¥–∏—Ç –∞–ø–¥–µ–π—Ç —è–≤–Ω–æ, —É–±–∏—Ä–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –Ω–∞–≥—Ä–∞–¥–µ, –¥–ª—è PPO –Ω–∞–≥—Ä–∞–¥–∞ –Ω—É–∂–Ω–∞, –∞ –∑–Ω–∞—á–∏—Ç –∫—Ç–æ-—Ç–æ –¥–æ–ª–∂–µ–Ω –µ–µ –≤—ã–¥–∞–≤–∞—Ç—å. –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º. –î–ª—è PPO, TRL –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞–≥—Ä–∞–¥—ã –æ—Ç –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–∫ (–Ω–æ —ç—Ç–æ –ø–æ–ø—Ä–∞–≤—è—Ç –≤ –±—É–¥—É—â–µ–º).\n",
        "\n",
        "–í–æ–∑—å–º–µ–º —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å —Å–∞–º–∏. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è preference dataset with implicit prompt ([—Å–º. –ø—Ä–∏–º–µ—Ä—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://huggingface.co/docs/trl/main/dataset_formats)). –¢–æ –µ—Å—Ç—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: chosen, rejected, –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∞—è—â–∞—è –≤ —Å–µ–±–µ –ø—Ä–æ–º–ø—Ç. –ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏, —ç—Ç–æ –≤—Å–µ –Ω–∞–¥–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤ —Ç–µ–º–ø–ª–µ–π—Ç —á–∞—Ç–∞.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:\n",
        "```python\n",
        "## Implicit prompt\n",
        "preference_example = {\n",
        "    \"chosen\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is blue.\"}\n",
        "    ],\n",
        "    \"rejected\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is green.\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –ª–æ—Å—Å –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è [—Ç—É—Ç](https://rlhfbook.com/c/07-reward-models.html). TRL –≤—Å–µ —Å–¥–µ–ª–∞–µ—Ç –∑–∞ –≤–∞—Å."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1337a76-ab6e-47f6-8d14-3430234b9858",
      "metadata": {
        "id": "e1337a76-ab6e-47f6-8d14-3430234b9858"
      },
      "outputs": [],
      "source": [
        "def to_implicit_prompt_preferences(example: dict[str, str]) -> dict[str, list[dict[str, str]]]:\n",
        "    \"\"\"\n",
        "    Converts an example into implicit prompt preferences format.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The user's input prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[dict[str, str]]]: A dictionary containing:\n",
        "            - \"chosen\": A list of messages forming the conversation for the chosen response.\n",
        "            - \"rejected\": A list of messages forming the conversation for the rejected response.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d",
      "metadata": {
        "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(to_implicit_prompt_preferences, remove_columns=[\"prompt\"])\n",
        "dataset = dataset.train_test_split(train_size=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495a42f6-2acc-4382-84ad-444d689892a2",
      "metadata": {
        "id": "495a42f6-2acc-4382-84ad-444d689892a2"
      },
      "source": [
        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—É–¥–µ–º —Ç—É –∂–µ –º–æ–¥–µ–ª—å, –æ–±—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –ø–æ–≤–µ—Ä—Ö. –î–ª—è –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `AutoModelForSequenceClassification`. –û–±—É—á–∏—Ç–µ —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å `RewardConfig` –∏ `RewardTrainer`. –û–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–¥–∞–∂–µ –º–µ–Ω—å—à–µ). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
      "metadata": {
        "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "# –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã —Ç—Ä–µ–Ω–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "# ==========================\n",
        "reward_model = todo()\n",
        "reward_model.train()\n",
        "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "reward_config = RewardConfig(\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    max_length=1024,\n",
        "    disable_dropout=True,\n",
        "    learning_rate=3e-4,\n",
        "    seed=42,\n",
        "    logging_steps=25,\n",
        "    report_to=\"wandb\" if ENABLE_WANDB else \"none\",\n",
        ")\n",
        "reward_trainer = RewardTrainer(\n",
        "    model=reward_model,\n",
        "    processing_class=tokenizer,\n",
        "    args=reward_config,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        ")\n",
        "\n",
        "reward_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af43201-f883-4399-9673-bca566decbc8",
      "metadata": {
        "id": "9af43201-f883-4399-9673-bca566decbc8"
      },
      "source": [
        "–ù–∞–≥—Ä–∞–¥–∞ –¥–ª—è chosen –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—à–µ —á–µ–º –¥–ª—è rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037",
      "metadata": {
        "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037"
      },
      "outputs": [],
      "source": [
        "inputs_chosen = tokenizer.apply_chat_template(dataset[\"test\"][0][\"chosen\"], tokenize=False)\n",
        "inputs_chosen = tokenizer(inputs_chosen, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "inputs_rejected = tokenizer.apply_chat_template(dataset[\"test\"][0][\"rejected\"], tokenize=False)\n",
        "inputs_rejected = tokenizer(inputs_rejected, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "score_chosen = reward_model(**inputs_chosen).logits[0].cpu().detach()\n",
        "score_rejected = reward_model(**inputs_rejected).logits[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d",
      "metadata": {
        "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d"
      },
      "outputs": [],
      "source": [
        "score_chosen, score_rejected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec6bca3",
      "metadata": {
        "id": "dec6bca3"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∏–º reward –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±\n",
        "\n",
        "reward_trainer.push_to_hub(f\"{REPO_NAME}-reward-model\", dataset_name=DATASET_ID, private=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f",
      "metadata": {
        "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ PPO [2 –±–∞–ª–ª–∞]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd",
      "metadata": {
        "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd"
      },
      "source": [
        "**WARN**: TRL –Ω–µ–¥–∞–≤–Ω–æ —Å–º–µ—Ä–∂–∏–ª–∏ –±–æ–ª—å—à–æ–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä PPO, –∑–∞–±—ã–≤ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –ø—Ä–∏–º–µ—Ä—ã ü•¥ü•¥ü•¥. –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–æ–¥, –∞ –Ω–µ –≤ –¥–æ–∫–º–µ–Ω—Ç–∞—Ü–∏—é. –ï—Å–ª–∏ –≤–∞–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –∑–Ω–∞—Ç—å –≤–∏–Ω–æ–≤–Ω—ã—Ö –≤ –ª–∏—Ü–æ:\n",
        "\n",
        "<a href=\"https://ibb.co/zTFL4GTt\"><img src=\"https://i.ibb.co/1tMpm8t4/Screenshot-2025-02-13-at-17-40-48.png\" alt=\"\" border=\"0\" /></a>\n",
        "\n",
        "–î–ª—è PPO –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–æ–ª—å–∫–æ prompt. –ü—Ä–∏–≤–µ–¥–∏—Ç–µ prompt –≤ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ (`tokenizer.apply_chat_template`). –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ `policy`, `ref_policy` –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ SmolLM2-135M-Instruct, –≤ –∫–∞—á–µ—Å—Ç–≤–µ `reward_model`, `value_model` —Å–≤–æ—é –æ–±—É—á–µ–Ω–Ω—É—é —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `PPOConfig` –∏ `PPOTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
      "metadata": {
        "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, padding_side=\"left\")\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "# ==========================\n",
        "value_model = todo()\n",
        "reward_model = todo()\n",
        "policy = todo()\n",
        "ref_policy = todo()\n",
        "\n",
        "\n",
        "def tokenize(example, tokenizer):\n",
        "    input_ids = todo()\n",
        "    return {\"input_ids\": input_ids}\n",
        "\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.remove_columns([\"chosen\", \"rejected\"])\n",
        "dataset = dataset.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, remove_columns=dataset.column_names)\n",
        "dataset = dataset.train_test_split()\n",
        "\n",
        "training_args = todo()\n",
        "trainer = todo()\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb",
      "metadata": {
        "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–∞—Ö. –í–ø–æ–ª–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ, —á—Ç–æ –≤—ã –Ω–µ —É–≤–∏–¥–∏—Ç–µ —Ç–∞–∫–æ–≥–æ —Å–∏–ª—å–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–∫ –ø–æ—Å–ª–µ DPO. PPO —Ç—Ä–µ–±—É–µ—Ç –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤, –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤ —Ü–µ–ª–æ–º –Ω–µ —Ç–∞–∫ —Å—Ç–∞–±–∏–ª–µ–Ω."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f399f65-81f2-4867-a776-09be56d4f7e1",
      "metadata": {
        "id": "5f399f65-81f2-4867-a776-09be56d4f7e1"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4",
      "metadata": {
        "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4"
      },
      "outputs": [],
      "source": [
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5424c50",
      "metadata": {
        "id": "e5424c50"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "model.push_to_hub(f\"{REPO_NAME}-ppo\")\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-ppo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4c547e-f9e7-42c4-acb4-513853326e76",
      "metadata": {
        "id": "6b4c547e-f9e7-42c4-acb4-513853326e76"
      },
      "source": [
        "## –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ [1 –±–∞–ª–ª]\n",
        "\n",
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–æ–¥–µ–ª—å (–æ—Ç DPO –∏ PPO).\n",
        "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ–≥–ø—Ä–æ–± –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –∏ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞.\n",
        "–ü–æ–¥–æ–π–¥–µ—Ç –ª—é–±–æ–π –Ω–µ —Å–∏–ª—å–Ω–æ –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Å hugging face.\n",
        "\n",
        "–°—á–∏—Ç–∞–µ—Ç –ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d521c8ba-b7f1-4d93-9410-53a753d6211a",
      "metadata": {
        "id": "d521c8ba-b7f1-4d93-9410-53a753d6211a"
      },
      "source": [
        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (–æ—Ç DPO –∏–ª–∏ PPO). –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ–≥–ø—Ä–æ–± –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –∫–∞–∫–∏—Ö –Ω–∏–±—É–¥—å –µ—â–µ, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞. –°—á–∏—Ç–∞–µ—Ç –ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1356ece6-c7d5-4431-8558-5be5908d8654",
      "metadata": {
        "id": "1356ece6-c7d5-4431-8558-5be5908d8654"
      },
      "outputs": [],
      "source": [
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "# ==========================\n",
        "todo()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b84b1b",
      "metadata": {
        "id": "69b84b1b"
      },
      "source": [
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã\n",
        "\n",
        "–í—ã —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã:\n",
        "- –û—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–∞ ü§ó (–º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å 3 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è): –∫–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞–Ω–∏—è, —Ä–µ–ø–æ—Ä—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ **[1 –±–∞–ª–ª]**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37de87c4",
      "metadata": {
        "id": "37de87c4"
      },
      "source": [
        "# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a0c0c7",
      "metadata": {
        "id": "33a0c0c7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "DPO_REPO_NAME = f\"{REPO_NAME}-dpo\"\n",
        "PPO_REPO_NAME = f\"{REPO_NAME}-ppo\"\n",
        "REWARD_MODEL_REPO_NAME = f\"{REPO_NAME}-reward-model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = AutoModelForCausalLM.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = check_model.to(device)\n",
        "check_model = check_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7605867",
      "metadata": {
        "id": "c7605867"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = check_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py_3_10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}